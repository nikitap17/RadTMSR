

library(fitdistrplus)
library(readr)
source("word_functions.R")
#source("circle2.R")
library(data.table)
#library(bibliometrix)
#library(yaml)
library(stringr)
#library(lattice)
#library(topicmodels)
library(udpipe)
library(igraph)
library(wordcloud)
library(Matrix)
library(ggplot2)
library(yaml)


## Word Frequency ------------------------------------------------------
## Import nounbydoc.csv file created with Python
nounbydoc <- read_csv("../RTMR_Output/nounbydoc.csv")
#View(nounbydoc)

### Negative Binomial function
select_words <- function(dtm, q = .95){
  d <- colSums(dtm)
  fit <- fitdist(d, "nbinom")
  thres <- qnbinom(q, size=fit$estimate["size"], mu=fit$estimate["mu"])
  return(d > thres)
}


# Frequency of word by doc (doc term matrix)
dtm <- udpipe::document_term_matrix(document_term_frequencies(nounbydoc))


# Negative binomial
set.seed(5348)
dtm_top <- dtm[, select_words(dtm, .95)]
dtm_top <- dtm_top[rowSums(dtm_top) > 0, ]


## Word frequencies
topterms <- colSums(dtm_top)
word_freq <- data.frame(Word = names(topterms), Frequency = topterms, row.names = NULL)
write.csv(word_freq, "../RTMR_Output/Keywords_freq.csv", row.names = FALSE)







## Topic Modelling (LDA) ----------------------------------------------

library(Rmpfr)
library(topicmodels)
library(udpipe)
library(slam)
library(tidytext)

# Functions:
harmonicMean <- function(logLikelihoods, precision = 2000L) {
  llMed <- median(logLikelihoods)
  as.double(llMed - log(mean(exp(-mpfr(logLikelihoods,
                                       prec = precision) + llMed))))
}
BIC <- function(ll, p, n){
  -2 * ll + p * log(n)
}
entropy <- function(post_prob){
  1 + (1/(nrow(post_prob) * 
            log(ncol(post_prob)))) * (sum(rowSums(post_prob * 
                                                    log(post_prob + 1e-12))))
}


# Preprocessing ####

df_lda <- nounbydoc
df_lda <- df_lda %>%
  bind_tf_idf(term, doc_id, freq)
summary(df_lda$tf_idf)
df_lda <- df_lda[order(df_lda$tf_idf),]

selected_words <- df_lda[!duplicated(df_lda$term), ]
selected_words <- selected_words$term[selected_words$tf_idf >= median(selected_words$tf_idf)]
df_lda <- df_lda[df_lda$term %in% selected_words, ]

dtm <- udpipe::document_term_matrix(document_term_frequencies(df_lda))
#yaml::write_yaml(dim(dtm), file = "Study1_lda_dims.txt")


# Build topic models

seqk <- seq(2, 20, 1)
burnin <- 1000
iter <- 1000
keep <- 50
set.seed(44773)
res_lda <- lapply(seqk, function(k) {
  topicmodels::LDA(
    dtm,
    k = k,
    method = "Gibbs",
    control = list(
      burnin = burnin,
      iter = iter,
      keep = keep
    )
  )
})

ll <- sapply(res_lda, function(x){harmonicMean(x@logLiks[-c(1:(burnin/keep))])})

K = seqk
N = nrow(dtm)
M = ncol(dtm)

parameters <- K*(M-1)+N*(K-1)
N <- nrow(dtm)
bics <- BIC(ll, parameters, N)

entropies <- sapply(res_lda, function(x){entropy(x@gamma)})

p <- ggplot(data.frame(K = seqk, Entropy = entropies), aes(x = K, y = Entropy)) + geom_path() +
  xlab('Number of topics') +
  scale_y_continuous(limits = c(0,1)) +
  theme_bw()

ggsave("../RTMR_Output/Keywords_entropies.png", p, device = "png", dpi = 600)
#ggsave("study1_entropies.svg", p, device = "svg")

p <- ggplot(data.frame(K = seqk, ll = ll), aes(x = K, y = ll)) + geom_path() +
  geom_vline(xintercept = (which.max(ll)+1), linetype = 2) +
  xlab('Number of topics') +
  geom_smooth(method = "lm", formula = y~log(x), se = FALSE)+
  theme_bw()

ggsave("../RTMR_Output/Keywords_ll.png", p, device = "png", dpi = 600)
#ggsave("study1_ll.svg", p, device = "svg")

p <- ggplot(data.frame(K = seqk, BIC = bics), aes(x = K, y = BIC)) + geom_path() +
  geom_vline(xintercept = (which.min(bics)+1), linetype = 2) +
  xlab('Number of topics') +
  geom_smooth(method = "lm", formula = y~x, se = FALSE)+
  theme_bw()

ggsave("../RTMR_Output/Keywords_BIC.png", p, device = "png", dpi = 600)
#ggsave("study1_BIC.svg", p, device = "svg")



## Co-occurrences -------------------------------------------------------

### Overall

set.seed(52)
cooc <- select_cooc(create_cooc(dtm_top), q = .975)
#write.csv(as.matrix(cooc), "s1_cooc.csv")
df_plot <- as_cooccurrence(cooc)
df_plot <- df_plot[!df_plot$term1 == df_plot$term2, ]
df_plot <- df_plot[order(df_plot$cooc, decreasing = TRUE), ]

df_plot$id <- apply(df_plot[, c("term1", "term2")], 1, function(x)paste0(sort(x), collapse = ""))
df_plot <- df_plot[!duplicated(df_plot$id), ]
df_plot_incl_radicalism <- df_plot
write.csv(df_plot_incl_radicalism, "../RTMR_Output/Keywords_cooc_inclrad.csv", row.names = FALSE)


### Exclude radicalism as a term

# Frequency of word by doc (doc term matrix)
nounbydoc_exclrad <- nounbydoc[nounbydoc$term != "radicalism"]

dtm <- udpipe::document_term_matrix(document_term_frequencies(nounbydoc_exclrad))
# Negative binomial
set.seed(5348)
dtm_top <- dtm[, select_words(dtm, .95)]
dtm_top <- dtm_top[rowSums(dtm_top) > 0, ]
topterms <- colSums(dtm_top)
word_freq <- data.frame(Word = names(topterms), Frequency = topterms, row.names = NULL)


set.seed(52)
cooc <- select_cooc(create_cooc(dtm_top), q = .975)
#write.csv(as.matrix(cooc), "s1_cooc.csv")
df_plot <- as_cooccurrence(cooc)
df_plot <- df_plot[!df_plot$term1 == df_plot$term2, ]
df_plot <- df_plot[order(df_plot$cooc, decreasing = TRUE), ]

df_plot$id <- apply(df_plot[, c("term1", "term2")], 1, function(x)paste0(sort(x), collapse = ""))
df_plot <- df_plot[!duplicated(df_plot$id), ]
write.csv(df_plot, "../RTMR_Output/Keywords_cooc_worad.csv", row.names = FALSE)



#### Adolescence ------------------------------------------------------

## choose only articles that include "adolescence"

ado_docs = unique(nounbydoc$doc_id[nounbydoc$term == "adolescence"])
nounbydoc_ado <- nounbydoc[nounbydoc$doc_id %in% ado_docs]


dtm <- udpipe::document_term_matrix(document_term_frequencies(nounbydoc_ado))
# Negative binomial
set.seed(5348)
dtm_top <- dtm[, select_words(dtm, .95)]
dtm_top <- dtm_top[rowSums(dtm_top) > 0, ]
topterms <- colSums(dtm_top)
word_freq <- data.frame(Word = names(topterms), Frequency = topterms, row.names = NULL)


set.seed(52)
cooc <- select_cooc(create_cooc(dtm_top), q = .975)
#write.csv(as.matrix(cooc), "s1_cooc.csv")
df_plot <- as_cooccurrence(cooc)
df_plot <- df_plot[!df_plot$term1 == df_plot$term2, ]
df_plot <- df_plot[order(df_plot$cooc, decreasing = TRUE), ]

df_plot$id <- apply(df_plot[, c("term1", "term2")], 1, function(x)paste0(sort(x), collapse = ""))
df_plot <- df_plot[!duplicated(df_plot$id), ]
write.csv(df_plot, "../RTMR_Output/Keywords_cooc_adolescence.csv", row.names = FALSE)






